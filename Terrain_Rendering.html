<!DOCTYPE html>
<html lang="en">
	<head>
		<title>three.js PathTracing Renderer - Terrain Rendering</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1">
		<style>

			html, body {
				width: 100%;
				height: 100%;
				font-family: Monospace;
				background-color: #000;
				color: #000;
				margin: 0px;
				overflow: hidden;
				touch-action: none;
			}
			
			#info {
				position: absolute;
				top: 5px;
				width: 100%;
				text-align: center;
				color: #ffffff;
			}		
			
		</style>
	</head>
	<body>

		<div id="container"> </div>
		<div id="info">three.js PathTracing Renderer - Terrain Rendering</div>
		
		<div id="cameraInfo" style="position:fixed; left:3%; bottom:2%; font-family:arial; color:rgb(255,255,255);">
		FOV: 50 / Aperture: 0.00 / FocusDistance: 1180 <br> 
		Samples: 0
		</div>

		<script src="js/three.min.js"> </script>
		<script src="js/pathTracingCommon.js"> </script>
		<script src="js/threex.keyboardstate.js"> </script>
		<script src="js/FirstPersonCameraControls.js"> </script>
		<script src="js/MobileJoystickControls.js"> </script>
		<script src="js/stats.min.js"> </script>
		
		
		<script id="pathTracingVertexShader" type="x-shader/x-vertex">
		
precision highp float;
precision highp int;

varying vec2 vUv;

void main()
{
	vUv = uv;
	gl_Position = vec4( position, 1.0 );
}

		</script>
		
		
		
		<script id="pathTracingFragmentShader" type="x-shader/x-fragment">
				
precision highp float;
precision highp int;
precision highp sampler2D;

uniform float uCameraUnderWater;
uniform float uWaterLevel;
uniform vec3 uSunDirection;

#include <pathtracing_uniforms_and_defines>

uniform sampler2D t_PerlinNoise;
uniform sampler2D t_GrayNoise;

#include <pathtracing_skymodel_defines>


//-----------------------------------------------------------------------

struct Ray { vec3 origin; vec3 direction; };
struct Quad { vec3 v0; vec3 v1; vec3 v2; vec3 v3; vec3 emission; vec3 color; int type; };
struct Box { vec3 minCorner; vec3 maxCorner; vec3 emission; vec3 color; int type; };
struct Intersection { vec3 normal; vec3 emission; vec3 color; vec2 uv; int type; };


#include <pathtracing_random_functions>

#include <pathtracing_sphere_intersect>

#include <pathtracing_plane_intersect>

#include <pathtracing_triangle_intersect>

#include <pathtracing_box_intersect>

#include <pathtracing_physical_sky_functions>

//----------------------------------------------------------------------------
float QuadIntersect( vec3 v0, vec3 v1, vec3 v2, vec3 v3, Ray r )
//----------------------------------------------------------------------------
{
	float tTri1 = TriangleIntersect( v0, v1, v2, r );
	float tTri2 = TriangleIntersect( v0, v2, v3, r );
	return min(tTri1, tTri2);
}


//---------------------------------------------------------------------------------------------------------
float DisplacementBoxIntersect( vec3 minCorner, vec3 maxCorner, Ray r )
//---------------------------------------------------------------------------------------------------------
{
	vec3 invDir = 1.0 / r.direction;
	vec3 tmin = (minCorner - r.origin) * invDir;
	vec3 tmax = (maxCorner - r.origin) * invDir;
	
	vec3 real_min = min(tmin, tmax);
	vec3 real_max = max(tmin, tmax);
	
	float minmax = min( min(real_max.x, real_max.y), real_max.z);
	float maxmin = max( max(real_min.x, real_min.y), real_min.z);
	
	// early out
	if (minmax < maxmin) return INFINITY;
	
	if (maxmin > 0.0) // if we are outside the box
	{
		return maxmin;	
	}
		
	if (minmax > 0.0) // else if we are inside the box
	{
		return minmax;
	}
				
	return INFINITY;
}




// WATER
/* Credit: some of the following water code is borrowed from https://www.shadertoy.com/view/Ms2SD1 posted by user 'TDM' */

#define ITER_FRAGMENT  4 // # of fractal iterations
#define SEA_HEIGHT     1.0 // this is how many units from the top of the ocean bounding box
#define SEA_FREQ       0.2 // wave density: lower = spread out, higher = close together
#define SEA_CHOPPY     1.0 // smaller beachfront-type waves, they travel in parallel
#define SEA_SPEED      0.02 // how quickly time passes
#define OCTAVE_M       mat2(1.6, 1.2, -1.2, 1.6)

float grayNoise( in vec2 uv )
{
	return texture2D( t_GrayNoise, uv ).x;
}

float sea_octave( vec2 uv, float choppy )
{
	uv += grayNoise(uv);        
	vec2 wv = 1.0 - abs(sin(uv));
	vec2 swv = abs(cos(uv));    
	wv = mix(wv, swv, wv);
	return pow(1.0 - pow(wv.x * wv.y, 0.65), choppy);
}

float getOceanWaterHeight( vec3 p )
{
	p.x *= 0.0005;
	p.z *= 0.0005;
	float freq = SEA_FREQ;
	float amp = SEA_HEIGHT;
	float choppy = SEA_CHOPPY;
	float sea_time = uTime * SEA_SPEED;
	
	vec2 uv = p.xz; uv.x *= 0.75;
	float d, h = 0.0;    
	for(int i = 0; i < ITER_FRAGMENT; i++)
	{        
		d =  sea_octave((uv + sea_time) * freq, choppy);
		d += sea_octave((uv - sea_time) * freq, choppy);
		h += d * amp;        
		uv *= OCTAVE_M; freq *= 1.9; amp *= 0.22;
		choppy = mix(choppy, 1.0, 0.2);
	}
	return h;
}


// CLOUDS
/* Credit: some of the following cloud code is borrowed from https://www.shadertoy.com/view/XtBXDw posted by user 'valentingalea' */

#define THICKNESS      20.0
#define ABSORPTION     0.45
#define N_MARCH_STEPS  10
#define N_LIGHT_STEPS  3

float noise3D( in vec3 p )
{
	return texture2D(t_PerlinNoise, p.xz ).x;
}

float lookup_noise2D( in vec2 uv )
{
	return texture2D(t_PerlinNoise, uv).x;
	
}

const mat3 m = mat3( 0.00,  0.80,  0.60,
                    -0.80,  0.36, -0.48,
		    -0.60, -0.48,  0.64 );

const mat2  m2 = mat2(0.8, 0.6, -0.6, 0.8);

float fbm( vec3 p )
{
	float t;
	t  = 0.5 * noise3D(p);   p = m * p * 2.6;
	t += 0.25 * noise3D(p);  p = m * p * 2.8;
	t += 0.125 * noise3D(p);// p = m * p * 3.0;

	return t;
}

float fbm_shadow( vec3 p )
{
	float t;
	t  = 0.5 * noise3D(p);
	t += 0.25 * noise3D(p);
	t += 0.125 * noise3D(p);
	
	return t;
}

float cloud_density( vec3 pos, float cov )
{
	vec3 p = pos * 0.003;
	float dens = fbm(p);
	dens *= smoothstep(cov, cov + 0.05, dens);

	return clamp(dens, 0.0, 1.0);	
}

float cloud_density_shadow( vec3 pos, float cov )
{
	vec3 p = pos * 0.003;
	float dens = fbm_shadow(p);
	dens *= smoothstep(cov, cov + 0.05, dens);

	return clamp(dens, 0.0, 1.0);	
}

float cloud_light( vec3 pos, vec3 dir_step, float cov )
{
	float T = 1.0; // transmitance
    	float dens;
    	float T_i;
	
	for (int i = 0; i < N_LIGHT_STEPS; i++) 
	{
		dens = cloud_density(pos, cov);
		T_i = exp(-ABSORPTION * dens);
		T *= T_i;
		pos += dir_step;
	}

	return T;
}

vec4 render_clouds( Ray eye, vec3 p, vec3 sunDirection )
{
	float march_step = THICKNESS / float(N_MARCH_STEPS);
	vec3 pos = p + vec3(uTime * -3.0, uTime * -0.5, uTime * -2.0);
	vec3 dir_step = eye.direction / clamp(eye.direction.y, 0.001, 1.0) * march_step;
	vec3 light_step = sunDirection * 10.0;
	
	float covAmount = (sin(mod(uTime * 0.2, TWO_PI))) * 0.5 + 0.5;
	float coverage = mix(0.55, 0.71, clamp(covAmount, 0.0, 1.0));
	float T = 1.0; // transmitance
	vec3 C = vec3(0); // color
	float alpha = 0.0;
	float dens;
	float T_i;
	float cloudLight;
	
	for (int i = 0; i < N_MARCH_STEPS; i++)
	{
		dens = cloud_density(pos, coverage);

		T_i = exp(-ABSORPTION * dens * march_step);
		T *= T_i;
		cloudLight = cloud_light(pos, light_step, coverage);
		C += T * cloudLight * dens * march_step;
		C = mix(C * 0.95, C, cloudLight);
		alpha += (1.0 - T_i) * (1.0 - alpha);
		pos += dir_step;
	}
	
	return vec4(C, alpha);
}

float checkCloudCover( vec3 sunDirection, vec3 p )
{
	float march_step = THICKNESS / float(N_MARCH_STEPS);
	vec3 pos = p + vec3(uTime * -3.0, uTime * -0.5, uTime * -2.0);
	vec3 dir_step = sunDirection / clamp(sunDirection.y, 0.001, 1.0) * march_step;
	
	float cov = abs(sin((uTime + 40.0) * 0.05));
	cov = mix(0.3, 0.7, cov);
	float alpha = 0.0;
	float dens;
	float T_i;
	
	for (int i = 0; i < N_MARCH_STEPS; i++)
	{
		dens = cloud_density_shadow(pos, cov);
		T_i = exp(-ABSORPTION * dens * march_step);
		alpha += (1.0 - T_i) * (1.0 - alpha);
		pos += dir_step;
	}
	
	return clamp(1.0 - alpha, 0.0, 1.0);
}


// TERRAIN

#define TERRAIN_FAR 200000.0
#define TERRAIN_HEIGHT 2000.0
#define TERRAIN_FREQ 2.0
#define TERRAIN_AMP 0.5
#define TERRAIN_SAMPLE_SCALE 0.00004

float terrain_map(vec2 p)
{
	float f = 0.0;
	float amplitude = TERRAIN_AMP;
	p *= TERRAIN_SAMPLE_SCALE;
	
	for (int i = 0; i < 2; i++)
	{
		f += amplitude * (lookup_noise2D(p) * 2.0 - 1.0);
		amplitude *= TERRAIN_AMP;
		p = m2 * p * TERRAIN_FREQ;	
	}
	
	return (f * TERRAIN_HEIGHT);
}

float terrain_map_detail(vec2 p)
{
	float f = 0.0;
	float amplitude = TERRAIN_AMP;
	p *= TERRAIN_SAMPLE_SCALE;
	
	for (int i = 0; i < 7; i++)
	{
		f += amplitude * (lookup_noise2D(p) * 2.0 - 1.0);
		amplitude *= TERRAIN_AMP;
		p = m2 * p * TERRAIN_FREQ;	
	}
	
	return (f * TERRAIN_HEIGHT);
}

float TerrainIntersect( Ray r )
{
	vec3 pos = r.origin;
	vec3 dir = (r.direction);
	float h = 0.0;
	float t = 0.0;
	
	for(int i = 0; i < 300; i++)
	{
		h = pos.y - terrain_map(pos.xz);
		if (t > TERRAIN_FAR || h < 1.0) break;
		t += h * 0.5;
		pos += dir * h * 0.5; 
	}
	return t < TERRAIN_FAR ? t : INFINITY;
}

vec3 terrain_calcNormal( vec3 pos, float t )
{
	vec2 eps = vec2(max(0.6, 0.001 * t), 0.0);
	vec2 p = pos.xz;
	return normalize( vec3( terrain_map_detail(p-eps.xy) - terrain_map_detail(p+eps.xy),
				2.0 * eps.x,
				terrain_map_detail(p-eps.yx) - terrain_map_detail(p+eps.yx) ) );
}

bool isLightSourceVisible( vec3 pos, vec3 n, vec3 dirToLight)
{
	float h = 1.0;
	float t = 0.0;
	float terrainHeight = TERRAIN_HEIGHT * 1.5;
	pos += n * 2.0;

	
	for(int i = 0; i < 150; i++)
	{
		
		h = pos.y - terrain_map(pos.xz);
		pos += dirToLight * h;
		if ( pos.y > terrainHeight || h < 1.0) break;
	}

	return pos.y > terrainHeight;
}


//-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
float SceneIntersect( Ray r, inout Intersection intersec, bool checkWater )
//-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
{
	vec3 normal;
        float d, dw;
	float t = INFINITY;
	vec3 hitPos; 

	// Terrain
	d = TerrainIntersect( r );
	if (d < t)
	{
		t = d;
		hitPos = r.origin + r.direction * t;
		intersec.normal = terrain_calcNormal(hitPos, t);
		intersec.emission = vec3(0);
		intersec.color = vec3(0);
		intersec.type = TERRAIN;
	}
	
	if (!checkWater)
		return t;
	
	d = PlaneIntersect( vec4(0, 1, 0, uWaterLevel), r );
	if ( d >= TERRAIN_FAR ) return t;
	vec3 hitWorldSpace = r.origin + r.direction * d;
	
	float waterWaveHeight = getOceanWaterHeight(hitWorldSpace);
	dw = DisplacementBoxIntersect( vec3(-INFINITY, -INFINITY, -INFINITY), vec3(INFINITY, waterWaveHeight + uWaterLevel, INFINITY), r);
	
	if (dw < t)
	{
		t = dw;
		//hitWorldSpace = r.origin + r.direction * dw;
		float eps = 1.0;
		float dx = getOceanWaterHeight(hitWorldSpace - vec3(eps,0,0)) - getOceanWaterHeight(hitWorldSpace + vec3(eps,0,0));
		float dy = eps * 2.0; // (the water wave height is a function of x and z, not dependent on y)
		float dz = getOceanWaterHeight(hitWorldSpace - vec3(0,0,eps)) - getOceanWaterHeight(hitWorldSpace + vec3(0,0,eps));
		intersec.normal = normalize(vec3(dx,dy,dz));
		intersec.emission = vec3(0);
		//intersec.color = vec3(0.5,0.7,0.8);
		intersec.color = vec3(0.1,0.5,0.3);
		intersec.type = REFR;
	}
		
	return t;
}


vec3 calcDirectLightingSun( vec3 mask, vec3 x, vec3 nl, vec3 sunDirection, Ray r, vec3 randVec )
{
	vec3 dirLight = vec3(0);
	Intersection shadowIntersec;
	
	// cast shadow ray from intersection point
	Ray shadowRay = Ray( x, normalize( sunDirection + (randVec * 0.01) ) );
	shadowRay.origin += nl * 2.0;
	
	float st = SceneIntersect(shadowRay, shadowIntersec, true);
	
	if ( st == INFINITY )
	{
		vec3 sunEmission = Get_Sky_Color(shadowRay, sunDirection);
                dirLight = mask * sunEmission * max(0.01, dot(shadowRay.direction, nl));
	}
	
	return dirLight;
}



//-----------------------------------------------------------------------
vec3 CalculateRadiance( Ray r, vec3 sunDirection, inout float seed )
//-----------------------------------------------------------------------
{
	vec3 randVec = vec3(rand(seed) * 2.0 - 1.0, rand(seed) * 2.0 - 1.0, rand(seed) * 2.0 - 1.0);
	Ray cameraRay = r;
	vec3 initialSkyColor = Get_Sky_Color(r, sunDirection);
	
	Ray skyRay = Ray( r.origin * vec3(0.05), normalize(vec3(r.direction.x, abs(r.direction.y), r.direction.z)) );
	float dc = SphereIntersect( 50000.0, vec3(skyRay.origin.x, -49900, skyRay.origin.z) + vec3(rand(seed) * 2.0), skyRay );
	vec3 skyPos = skyRay.origin + skyRay.direction * dc;
	vec4 cld = render_clouds(skyRay, skyPos, sunDirection);
	
	Intersection intersec;
	vec3 accumCol = vec3(0.0);
        vec3 mask = vec3(1.0);
	vec3 n, nl, x;
	vec3 firstX = vec3(0);
        
	float t = INFINITY;
	int previousIntersecType = -1;
	bool checkWater = true;
	bool skyHit = false;
	bool bounceIsSpecular = true;
	
	
        for (int depth = 0; depth < 2; depth++)
	{
		
		t = SceneIntersect(r, intersec, checkWater);
		
		// ray hits sky first
		if (t == INFINITY && depth == 0 )
		{
			skyHit = true;
			firstX = skyPos;
			accumCol = initialSkyColor;
			break;	
		}
		
		
		// if ray bounced off of water and hits sky
		if ( t == INFINITY && previousIntersecType == REFR )
		{
			//if (bounceIsSpecular) // prevents sun 'fireflies' on diffuse surfaces
			{
				accumCol = mask * Get_Sky_Color(r, sunDirection);
			}
			
			skyHit = true; // uncomment for clouds reflection in water
			firstX = skyPos;
			
			break;	
		}
		
		
		/*
		// if ray bounced off of diffuse material (i.e. scene geometric objects) and hits sky
		if (t == INFINITY && previousIntersecType == DIFF)
		{	
			float rDotSun = max(0.0, dot(r.direction, sunDirection));
			if (rDotSun < 0.99) // prevents sun 'fireflies' on diffuse surfaces
				accumCol += mask * Get_Sky_Color(r, sunDirection);
				
			break;
		}
		*/
		
		// useful data 
		n = intersec.normal;
                nl = dot(n,r.direction) <= 0.0 ? normalize(n) : normalize(n * -1.0);
		x = r.origin + r.direction * t;
		
		if (depth == 0) 
			firstX = x;
		
		// ray hits terrain
		if (intersec.type == TERRAIN)
		{
			float noiseValue = lookup_noise2D(vec2(x.xz*0.0004));
			vec3 terrainColor = vec3(0.1, 0.04, 0.02) * noiseValue;
			vec3 snowColor = vec3(0.6);
			vec3 up = vec3(0, 1, 0);
			float dotUp_SunDirection = max(0.0, dot(up, sunDirection));
			float terrainHeight = clamp( x.y / (TERRAIN_HEIGHT * 0.4), 0.0, 3.0 );
			
			if (x.y > uWaterLevel && n.y > 1.0 - terrainHeight)
			{
				terrainColor = snowColor;
			}
				
			if ( isLightSourceVisible(x, n, normalize(sunDirection + (randVec * 0.005))) ) // in sunlight
			{
				vec3 sunColor = clamp(Get_Sky_Color(Ray(x, normalize(sunDirection + (randVec * 0.05))), sunDirection), 0.0, 1.0);
				if (terrainColor == snowColor)
					accumCol = mask * terrainColor * mix(sunColor, vec3(1), dotUp_SunDirection) *
						max(0.3, dot(normalize(n + sunDirection), sunDirection)) * clamp(dotUp_SunDirection, 0.7, 1.0);
				else	
					accumCol = mask * terrainColor * max(0.0, dot(n, sunDirection));	
			}
			else // in shadow
			{
				if (terrainColor == snowColor)
					accumCol = mask * terrainColor * max(0.0, dot(normalize(n + (up * 0.5)), up)) * dotUp_SunDirection;
				else	
					accumCol = mask * terrainColor * max(0.0, dot(n, up)) * 0.03;		
			} 	
			
			break;
		}
		
		if (intersec.type == REFR)  // Ideal dielectric REFRACTION
		{
			checkWater = false;
			
			float nc = 1.0; // IOR of air
			float nt = 1.33; // IOR of water
			float nnt = dot(n,nl) > 0.0 ? (nc / nt) : (nt / nc); // Ray from outside going in?
			vec3 tdir = refract(r.direction, nl, nnt);
				
			// Original Fresnel equations
			float cosThetaInc = dot(nl, r.direction);
			float cosThetaTra = dot(nl, tdir);
			float coefS = (nc * cosThetaInc - nt * cosThetaTra) / (nc * cosThetaInc + nt * cosThetaTra);
			float coefP = (nc * cosThetaTra - nt * cosThetaInc) / (nc * cosThetaTra + nt * cosThetaInc);
			float Re = ( (coefS * coefS) + (coefP * coefP) ) * 0.5; // Unpolarized
			if (uCameraUnderWater > 0.0)
				Re *= 0.2;
			else Re *= 2.0; // tweak to add more reflectivity to water
			if (rand(seed) < Re) // reflect ray from surface
			{
				r = Ray( x, reflect(r.direction, nl) );
				r.origin += r.direction * 2.0;
				previousIntersecType = REFR;
				continue;	
			}
			else // transmit ray through surface
			{
				mask *= intersec.color;
				r = Ray(x, tdir);
				r.origin += r.direction * 2.0;
				previousIntersecType = REFR;
				continue;
			}
		} // end if (intersec.type == REFR)
		
	} // end for (int depth = 0; depth < 2; depth++)
	
	
	// atmospheric haze effect (aerial perspective)
	float hitDistance;
	
	if ( skyHit ) // sky and clouds
	{
		vec3 cloudColor = cld.rgb / (cld.a + 0.00001);
		vec3 sunColor = clamp(Get_Sky_Color( Ray(skyPos, normalize((randVec * 0.03) + sunDirection)), sunDirection ), 0.0, 1.0);
		
		cloudColor *= mix(sunColor, vec3(1), max(0.0, dot(vec3(0,1,0), sunDirection)) );
		cloudColor = mix(initialSkyColor, cloudColor, clamp(cld.a, 0.0, 1.0));
		
		hitDistance = distance(skyRay.origin, skyPos);
		accumCol = mask * mix( accumCol, cloudColor, clamp( exp2( -hitDistance * 0.003 ), 0.0, 1.0 ) );
	}	
	else // terrain and other objects
	{
		hitDistance = distance(cameraRay.origin, firstX);
		if (hitDistance > 90000.0)
			accumCol = mix( initialSkyColor, accumCol, clamp(  exp( -log(hitDistance * 0.0001) ), 0.0, 1.0 ) );
		   else accumCol = mix( initialSkyColor, accumCol, clamp( exp2( -log(hitDistance * 0.0001) ), 0.0, 1.0 ) );
	}
	
	// underwater fog effect
	hitDistance = distance(cameraRay.origin, firstX);
	hitDistance *= uCameraUnderWater;
	accumCol = mix( vec3(0.0,0.05,0.05), accumCol, clamp( exp2( -hitDistance * 0.001 ), 0.0, 1.0 ) );
	
	return vec3(max(vec3(0), accumCol));      
}

/*
//-----------------------------------------------------------------------
void SetupScene(void)
//-----------------------------------------------------------------------
{
	vec3 z  = vec3(0);// No color value, Black        
	
}
*/

void main( void )
{
	vec3 camPos     = vec3( uCameraMatrix[3][0],  uCameraMatrix[3][1],  uCameraMatrix[3][2]);
	
    	vec3 camRight   = vec3( uCameraMatrix[0][0],  uCameraMatrix[0][1],  uCameraMatrix[0][2]);
    	vec3 camUp      = vec3( uCameraMatrix[1][0],  uCameraMatrix[1][1],  uCameraMatrix[1][2]);
	vec3 camForward = vec3(-uCameraMatrix[2][0], -uCameraMatrix[2][1], -uCameraMatrix[2][2]);
	
	// seed for rand() function
	float seed = mod(uSampleCounter,1000.0) * uRandomVector.x - uRandomVector.y + uResolution.y * gl_FragCoord.x / uResolution.x + uResolution.x * gl_FragCoord.y / uResolution.y;
	
	float r1 = 2.0 * rand(seed);
	float r2 = 2.0 * rand(seed);
	
	vec2 pixelPos = vec2(0);
	vec2 offset = vec2(0);
	
	//if ( !uCameraIsMoving ) 
	{
		offset.x = r1 < 1.0 ? sqrt(r1) - 1.0 : 1.0 - sqrt(2.0 - r1);
        	offset.y = r2 < 1.0 ? sqrt(r2) - 1.0 : 1.0 - sqrt(2.0 - r2);
	}
	

	offset /= (uResolution);
	pixelPos = (2.0 * (vUv + offset) - 1.0);
	vec3 rayDir = normalize( pixelPos.x * camRight * uULen + pixelPos.y * camUp * uVLen + camForward );
	
	// depth of field
	vec3 focalPoint = uFocusDistance * rayDir;
	float randomAngle = rand(seed) * TWO_PI; // pick random point on aperture
	float randomRadius = rand(seed) * uApertureSize;
	vec3  randomAperturePos = ( cos(randomAngle) * camRight + sin(randomAngle) * camUp ) * randomRadius;
	// point on aperture to focal point
	vec3 finalRayDir = normalize(focalPoint - randomAperturePos);
    
	Ray ray = Ray( camPos + randomAperturePos, finalRayDir );

	// not needed in this demo, all objects are procedurally generated
	//SetupScene(); 

	// perform path tracing and get resulting pixel color
	vec3 pixelColor = CalculateRadiance( ray, uSunDirection, seed );
	
	vec3 previousColor = texture2D(tPreviousTexture, vUv).rgb;
	
	if ( uCameraIsMoving )
	{
		previousColor *= 0.85; // motion-blur trail amount (old image)
		pixelColor *= 0.15; // brightness of new image (noisy)
	}
	else
	{
		previousColor *= 0.9; // motion-blur trail amount (old image)
		pixelColor *= 0.1; // brightness of new image (noisy)
	}
	
	
	gl_FragColor = vec4( pixelColor + previousColor, 1.0 );	
}

		</script>
		
		
		<script>
			
			var SCREEN_WIDTH;
			var SCREEN_HEIGHT;
			var container, stats;
			var controls;
			var pathTracingScene, screenTextureScene, screenOutputScene;
			var pathTracingUniforms, screenTextureUniforms, screenOutputUniforms;
			var PerlinNoiseTexture, GrayNoiseTexture;
			var pathTracingDefines;
			var pathTracingGeometry, pathTracingMaterial, pathTracingMesh;
			var screenTextureGeometry, screenTextureMaterial, screenTextureMesh;
			var screenOutputGeometry, screenOutputMaterial, screenOutputMesh;
			var pathTracingRenderTarget, screenOutputRenderTarget;
			var quadCamera, worldCamera;
			var renderer, clock;
			var frameTime, elapsedTime;
			var fovScale;
			var increaseFOV = false;
			var decreaseFOV = false;
			var apertureSize = 0.0;
			var increaseAperture = false;
			var decreaseAperture = false;
			var focusDistance = 1180.0;
			var increaseFocusDist = false;
			var decreaseFocusDist = false;
			var pixelRatio = 0.5;
			var TWO_PI = Math.PI * 2;
			var sunAngle = 0;
			var sunDirection = new THREE.Vector3();
			var randomVector = new THREE.Vector3();
			var sampleCounter = 1.0;
			var keyboard = new THREEx.KeyboardState();
			var cameraIsMoving = false;
			var cameraJustStartedMoving = false;
			var cameraRecentlyMoving = false;
			var isPaused = true;
			var oldYawRotation, oldPitchRotation;
			var mobileJoystickControls = null;
			var oldDeltaX = 0, oldDeltaY = 0;
			var newDeltaX = 0, newDeltaY = 0;
			var mobileControlsMoveX = 0;
			var mobileControlsMoveY = 0;
			var stillFlagX = true, stillFlagY = true;
			var oldPinchWidthX = 0;
			var oldPinchWidthY = 0;
			var pinchDeltaX = 0;
			var pinchDeltaY = 0;
			var camFlightSpeed = 300;
			var waterLevel = -500.0;
			var cameraUnderWater = false;
			var fontAspect;
			
			// the following variables will be used to calculate rotations and directions from the camera
			var cameraDirectionVector = new THREE.Vector3();//for moving where the camera is looking
			var cameraRightVector = new THREE.Vector3();//for strafing the camera right and left
			var cameraUpVector = new THREE.Vector3();//for moving camera up and down
			var cameraWorldQuaternion = new THREE.Quaternion();//for rotating scene objects to match camera's current rotation
			var cameraControlsObject;//for positioning and moving the camera itself
			var cameraControlsYawObject;//allows access to control camera's left/right movements through mobile input
			var cameraControlsPitchObject;//allows access to control camera's up/down movements through mobile input

			var PI_2 = Math.PI / 2;//used by controls below
			
			var infoElement = document.getElementById( 'info' );
			infoElement.style.cursor = "default";
			infoElement.style.webkitUserSelect = "none";
			infoElement.style.MozUserSelect = "none";
			
			var cameraInfoElement = document.getElementById( 'cameraInfo' );
			cameraInfoElement.style.cursor = "default";
			cameraInfoElement.style.webkitUserSelect = "none";
			cameraInfoElement.style.MozUserSelect = "none";
			
			var mouseControl = true;
			
			
			function onMouseWheel( event ) {

				event.preventDefault();
				event.stopPropagation();

				if ( event.deltaY > 0 ) {
					
					increaseFOV = true;
				
				} else if ( event.deltaY < 0 ) {
					
					decreaseFOV = true;
					
				}

			}
			
			
			init();
			
			
		     // function init( meshes ) {
			function init() {
				
				if ( 'createTouch' in document ) {
					mouseControl = false;
					pixelRatio = 0.5;
					
					mobileJoystickControls = new MobileJoystickControls ({
						//showJoystick: true,
						enableMultiTouch: true
					});	
				}

				// if on mobile device, unpause the app because there is no ESC key and no mouse capture to do
				if ( !mouseControl )
					isPaused = false;

				if (mouseControl) {

					window.addEventListener( 'wheel', onMouseWheel, false );

					document.body.addEventListener("click", function() {
						this.requestPointerLock = this.requestPointerLock || this.mozRequestPointerLock;
						this.requestPointerLock();
					}, false);

					window.addEventListener("click", function(event) {
						event.preventDefault();	
					}, false);
					window.addEventListener("dblclick", function(event) {
						event.preventDefault();	
					}, false);


					var pointerlockChange = function ( event ) {

						if ( document.pointerLockElement === document.body || 
						    document.mozPointerLockElement === document.body || document.webkitPointerLockElement === document.body ) {

							isPaused = false;

						} else {

							isPaused = true;

						}

					};

					// Hook pointer lock state change events
					document.addEventListener( 'pointerlockchange', pointerlockChange, false );
					document.addEventListener( 'mozpointerlockchange', pointerlockChange, false );
					document.addEventListener( 'webkitpointerlockchange', pointerlockChange, false );

				}
				
				renderer = new THREE.WebGLRenderer();
				renderer.autoClear = false;
				// 1 is full resolution, 0.5 is half, 0.25 is quarter, etc. (must be > than 0.0)
				renderer.setPixelRatio(pixelRatio);
				renderer.setSize( window.innerWidth, window.innerHeight );
				renderer.context.getExtension('OES_texture_float');
				
				container = document.getElementById( 'container' );
				container.appendChild( renderer.domElement );
				
				stats = new Stats();
				stats.domElement.style.position = 'absolute';
				stats.domElement.style.top = '0px';
				stats.domElement.style.cursor = "default";
				stats.domElement.style.webkitUserSelect = "none";
				stats.domElement.style.MozUserSelect = "none";
				container.appendChild( stats.domElement );
				
				window.addEventListener( 'resize', onWindowResize, false );
				
				clock = new THREE.Clock();
				
				pathTracingScene = new THREE.Scene();
				screenTextureScene = new THREE.Scene();
				screenOutputScene = new THREE.Scene();
				
				// quadCamera is simply the camera to help render the full screen quad (2 triangles),
				// hence the name.  It is an Orthographic camera that sits facing the view plane, which serves as
				// the window into our 3d world. This camera will not move or rotate for the duration of the app.
				quadCamera = new THREE.OrthographicCamera( -1, 1, 1, -1, 0, 1 );
				screenTextureScene.add(quadCamera);
				screenOutputScene.add(quadCamera);
				
				// worldCamera is the dynamic camera 3d object that will be positioned, oriented and 
				// constantly updated inside the 3d scene.  Its view will ultimately get passed back to the 
				// stationary quadCamera, which renders the scene to a fullscreen quad (made up of 2 large triangles).
				worldCamera = new THREE.PerspectiveCamera(80, window.innerWidth / window.innerHeight, 1, 1000);
				pathTracingScene.add(worldCamera);
				
				controls = new FirstPersonCameraControls( worldCamera );
							
				cameraControlsObject = controls.getObject();
				cameraControlsYawObject = controls.getYawObject();
				cameraControlsPitchObject = controls.getPitchObject();
				
				pathTracingScene.add( cameraControlsObject );

				// uncomment for aerial panorama
				cameraControlsObject.position.set(-53, 1055, 196);
				cameraControlsYawObject.rotation.y = 4.0;
				cameraControlsPitchObject.rotation.x = -0.1;

				// uncomment for tall mountain / lake view
				//cameraControlsObject.position.set(1397, 1035, -1840); 
				//cameraControlsYawObject.rotation.y = 2.0;
				//cameraControlsPitchObject.rotation.x = -0.4;

				// uncomment for right above lake view
				//cameraControlsObject.position.set(2272, -383, -605); 
				//cameraControlsYawObject.rotation.y = 4.6;
				//cameraControlsPitchObject.rotation.x = 0.0;
				
				
				
				oldYawRotation = cameraControlsYawObject.rotation.y;
				oldPitchRotation = cameraControlsPitchObject.rotation.x;
				
				// now that we moved and rotated the camera, the following line force-updates the camera's matrix,
				//  and prevents rendering the very first frame in the old default camera position/orientation
				cameraControlsObject.updateMatrixWorld(true);
				
				pathTracingRenderTarget = new THREE.WebGLRenderTarget( (window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter,
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					type: THREE.FloatType,
					depthBuffer: false,
					stencilBuffer: false
				} );
				pathTracingRenderTarget.texture.generateMipmaps = false;
				
				screenTextureRenderTarget = new THREE.WebGLRenderTarget( (window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter, 
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					type: THREE.FloatType,
					depthBuffer: false,
					stencilBuffer: false
				} );
				screenTextureRenderTarget.texture.generateMipmaps = false;
				

				PerlinNoiseTexture = new THREE.TextureLoader().load( 'textures/perlin256.png' );
				PerlinNoiseTexture.wrapS = THREE.RepeatWrapping;
				PerlinNoiseTexture.wrapT = THREE.RepeatWrapping;
				PerlinNoiseTexture.flipY = false;
				PerlinNoiseTexture.minFilter = THREE.LinearFilter;
				PerlinNoiseTexture.generateMipmaps = false;
				
				GrayNoiseTexture = new THREE.TextureLoader().load( 'textures/grayNoise256.png' );
				GrayNoiseTexture.wrapS = THREE.RepeatWrapping;
				GrayNoiseTexture.wrapT = THREE.RepeatWrapping;
				GrayNoiseTexture.flipY = false;
				GrayNoiseTexture.minFilter = THREE.LinearFilter; 
				GrayNoiseTexture.generateMipmaps = false;
				
				
				pathTracingGeometry = new THREE.PlaneBufferGeometry( 2, 2 );

				pathTracingUniforms = {
					
					tPreviousTexture: { type: "t", value: screenTextureRenderTarget.texture },
					
					t_PerlinNoise: { type: "t", value: PerlinNoiseTexture },
					t_GrayNoise: { type: "t", value: GrayNoiseTexture },
					
					uCameraIsMoving: { type: "b1", value: false },
					uCameraJustStartedMoving: { type: "b1", value: false },
					
					uCameraUnderWater: { type: "f", value: 0.0 },
					uWaterLevel: { type: "f", value: 0.0 },
					uTime: { type: "f", value: 0.0 },
					uSampleCounter: { type: "f", value: 0.0 },
					uULen: { type: "f", value: 1.0 },
					uVLen: { type: "f", value: 1.0 },
					uApertureSize: { type: "f", value: 0.0 },
					uFocusDistance: { type: "f", value: 1180.0 },
					
					uResolution: { type: "v2", value: new THREE.Vector2() },
					
					uRandomVector: { type: "v3", value: new THREE.Vector3() },
					uSunDirection: { type: "v3", value: new THREE.Vector3() },
				
					uCameraMatrix: { type: "m4", value: new THREE.Matrix4() }
	
				};
				
				/*
				pathTracingDefines = {
					NUMBER_OF_TRIANGLES: total_number_of_triangles
				};
				*/
			
				pathTracingMaterial = new THREE.ShaderMaterial( {
					uniforms: pathTracingUniforms,
					//defines: pathTracingDefines,
					vertexShader: document.getElementById( 'pathTracingVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'pathTracingFragmentShader' ).textContent,
				        depthTest: false,
                                        depthWrite: false
                                } );

				pathTracingMesh = new THREE.Mesh( pathTracingGeometry, pathTracingMaterial );
				pathTracingScene.add( pathTracingMesh );
				
				
				
				// the following keeps the large scene ShaderMaterial quad right in front 
				//   of the camera at all times. This is necessary because without it, the scene 
				//   quad will fall out of view and get clipped when the camera rotates past 180 degrees.
				worldCamera.add( pathTracingMesh );
				
				
				
				screenTextureGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenTextureMaterial = new THREE.ShaderMaterial( {
					uniforms: screenTextureShader.uniforms,
					vertexShader: screenTextureShader.vertexShader,
					fragmentShader: screenTextureShader.fragmentShader,
					depthWrite: false,
					depthTest: false
				} );
				
				screenTextureMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;
				
				screenTextureMesh = new THREE.Mesh(screenTextureGeometry, screenTextureMaterial);
				screenTextureScene.add(screenTextureMesh);
				
				
				
				screenOutputGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenOutputMaterial = new THREE.ShaderMaterial( {
					uniforms: screenOutputShader.uniforms,
					vertexShader: screenOutputShader.vertexShader,
					fragmentShader: screenOutputShader.fragmentShader,
					depthWrite: false,
					depthTest: false
				} );
				
				screenOutputMaterial.uniforms.tTexture0.value = pathTracingRenderTarget.texture;
				
				screenOutputMesh = new THREE.Mesh(screenOutputGeometry, screenOutputMaterial);
				screenOutputScene.add(screenOutputMesh);
				

				/*
				// Fullscreen API
				document.addEventListener("click", function() {
					
					if ( !document.fullscreenElement && !document.mozFullScreenElement && !document.webkitFullscreenElement ) {

						if (document.documentElement.requestFullscreen) {
							document.documentElement.requestFullscreen();
							
						} else if (document.documentElement.mozRequestFullScreen) {
							document.documentElement.mozRequestFullScreen();
						
						} else if (document.documentElement.webkitRequestFullscreen) {
							document.documentElement.webkitRequestFullscreen();
						
						}

					}
				});
				*/
				
				// onWindowResize() must be at the end of the init() function
				onWindowResize();
				
				// everything is set up, now we can start animating
				animate();
				
			} // end function init()
			
			
			
			function onWindowResize( event ) {
				
				SCREEN_WIDTH = window.innerWidth;
				SCREEN_HEIGHT = window.innerHeight;
				
				renderer.setPixelRatio(pixelRatio);
				renderer.setSize( SCREEN_WIDTH, SCREEN_HEIGHT );
				
				fontAspect = (SCREEN_WIDTH / 175) * (SCREEN_HEIGHT / 200);
				if (fontAspect > 25) fontAspect = 25;
				if (fontAspect < 4) fontAspect = 4;
				fontAspect *= 2;
				
				pathTracingUniforms.uResolution.value.x = renderer.context.drawingBufferWidth;
				pathTracingUniforms.uResolution.value.y = renderer.context.drawingBufferHeight;
				
				pathTracingRenderTarget.setSize( renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight );
				screenTextureRenderTarget.setSize( renderer.context.drawingBufferWidth, renderer.context.drawingBufferHeight );
				
				worldCamera.aspect = renderer.domElement.clientWidth / renderer.domElement.clientHeight;
				worldCamera.updateProjectionMatrix();
				
				// the following scales all scene objects by the worldCamera's field of view,
				// taking into account the screen aspect ratio and multiplying the uniform uULen,
				// the x-coordinate, by this ratio
				fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
				pathTracingUniforms.uVLen.value = Math.tan(fovScale);
				pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
				
				if ( !mouseControl ) {
					
					button1Element.style.display = "";
					button2Element.style.display = "";
					button3Element.style.display = "";
					button4Element.style.display = "";
					button5Element.style.display = "";
					button6Element.style.display = "";
					// check if mobile device is in portrait or landscape mode and position buttons accordingly
					if (SCREEN_WIDTH < SCREEN_HEIGHT) {
						
						button1Element.style.right = 36 + "%";
						button2Element.style.right = 2 + "%";
						button3Element.style.right = 16 + "%";
						button4Element.style.right = 16 + "%";
						button5Element.style.right = 3 + "%";
						button6Element.style.right = 3 + "%";

						button1Element.style.bottom = 5 + "%";
						button2Element.style.bottom = 5 + "%";
						button3Element.style.bottom = 13 + "%";
						button4Element.style.bottom = 2 + "%";
						button5Element.style.bottom = 25 + "%";
						button6Element.style.bottom = 18 + "%";
						
					}
					else {
						
						button1Element.style.right = 22 + "%";
						button2Element.style.right = 3 + "%";
						button3Element.style.right = 11 + "%";
						button4Element.style.right = 11 + "%";
						button5Element.style.right = 3 + "%";
						button6Element.style.right = 3 + "%";

						button1Element.style.bottom = 10 + "%";
						button2Element.style.bottom = 10 + "%";
						button3Element.style.bottom = 26 + "%";
						button4Element.style.bottom = 4 + "%";
						button5Element.style.bottom = 48 + "%";
						button6Element.style.bottom = 34 + "%";
						
					}
					
				} // end if ( !mouseControl ) {
				
			} // end function onWindowResize( event )
			
			
			
			function animate() {
				
				requestAnimationFrame( animate );
				
				frameTime = clock.getDelta();
				
				elapsedTime = clock.getElapsedTime() % 1000;
				
				// reset flags
				cameraIsMoving = false;
				cameraJustStartedMoving = false;
				
				// check user controls
				if (mouseControl) {
					// movement detected
					if ( oldYawRotation != cameraControlsYawObject.rotation.y || 
					      oldPitchRotation != cameraControlsPitchObject.rotation.x ) {
	
						cameraIsMoving = true;
					}
					
					// save state for next frame
					oldYawRotation = cameraControlsYawObject.rotation.y;
					oldPitchRotation = cameraControlsPitchObject.rotation.x;
					
				} // end if (mouseControl)
			
				// if not playing on desktop, get input from the mobileJoystickControls
				if ( !mouseControl ) {

					newDeltaX = joystickDeltaX;
					
					if (newDeltaX) {
						
						mobileControlsMoveX = oldDeltaX - newDeltaX;
						// smooth out jerkiness if camera was sitting still 
						if (stillFlagX) {
							mobileControlsMoveX *= 0.1;
							stillFlagX = false;
						}
						// mobileJoystick X movement (left and right) affects camera rotation around the Y axis	
						cameraControlsYawObject.rotation.y += (mobileControlsMoveX) * 0.01;
					}
					
					newDeltaY = joystickDeltaY;
					
					if (newDeltaY) {
						
						mobileControlsMoveY = oldDeltaY - newDeltaY;
						// smooth out jerkiness if camera was sitting still
						if (stillFlagY) {
							mobileControlsMoveY *= 0.1;
							stillFlagY = false;
						}
						// mobileJoystick Y movement (up and down) affects camera rotation around the X axis	
						cameraControlsPitchObject.rotation.x += (mobileControlsMoveY) * 0.01;
					}
					
					// clamp the camera's vertical movement (around the x-axis) to the scene's 'ceiling' and 'floor',
					// so you can't accidentally flip the camera upside down
					cameraControlsPitchObject.rotation.x = Math.max( - PI_2, Math.min( PI_2, cameraControlsPitchObject.rotation.x ) );
					
					// save state for next frame
					oldDeltaX = newDeltaX;
					oldDeltaY = newDeltaY;
					
					// movement detected
					if ( newDeltaX || newDeltaY ) {
						
						cameraIsMoving = true;
					}
					else {
						stillFlagX = true;
						stillFlagY = true;
					}
					
					newPinchWidthX = pinchWidthX;
					newPinchWidthY = pinchWidthY;
					pinchDeltaX = newPinchWidthX - oldPinchWidthX;
					pinchDeltaY = newPinchWidthY - oldPinchWidthY;
					
					if( Math.abs(pinchDeltaX) > Math.abs(pinchDeltaY) ) {
						if (pinchDeltaX < -3) increaseFOV = true;
						if (pinchDeltaX >  3) decreaseFOV = true;
					}
					
					if( Math.abs(pinchDeltaY) >= Math.abs(pinchDeltaX) ) {
						if (pinchDeltaY >  1) increaseAperture = true;
						if (pinchDeltaY < -1) decreaseAperture = true;
					}
					
					// save state for next frame
					oldPinchWidthX = newPinchWidthX;
					oldPinchWidthY = newPinchWidthY;
					
				} // end if ( !mouseControl )
				
				// this gives us a vector in the direction that the camera is pointing,
				// which will be useful for moving the camera 'forward' and shooting projectiles in that direction
				controls.getDirection(cameraDirectionVector);
				cameraDirectionVector.normalize();
				controls.getUpVector(cameraUpVector);
				controls.getRightVector(cameraRightVector);

				// the following gives us a rotation quaternion (4D vector), which will be useful for 
				// rotating scene objects to match the camera's rotation
				worldCamera.getWorldQuaternion(cameraWorldQuaternion);
				
				// allow flying camera
				if ( (keyboard.pressed('W') || button3Pressed) && !(keyboard.pressed('S') || button4Pressed) ) {

					cameraControlsObject.position.add(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('S') || button4Pressed) && !(keyboard.pressed('W') || button3Pressed) ) {

					cameraControlsObject.position.sub(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('A') || button1Pressed) && !(keyboard.pressed('D') || button2Pressed) ) {

					cameraControlsObject.position.sub(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('D') || button2Pressed) && !(keyboard.pressed('A') || button1Pressed) ) {

					cameraControlsObject.position.add(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( keyboard.pressed('Q') && !keyboard.pressed('Z') ) {

					cameraControlsObject.position.add(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( keyboard.pressed('Z') && !keyboard.pressed('Q') ) {

					cameraControlsObject.position.sub(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('up') || button5Pressed) && !(keyboard.pressed('down') || button6Pressed) ) {
					
					increaseFocusDist = true;
				}
				if ( (keyboard.pressed('down') || button6Pressed) && !(keyboard.pressed('up') || button5Pressed) ) {
					
					decreaseFocusDist = true;
				}
				if ( keyboard.pressed('right') && !keyboard.pressed('left') ) {
					
					increaseAperture = true;
				}
				if ( keyboard.pressed('left') && !keyboard.pressed('right') ) {
					
					decreaseAperture = true;
				}
				
				if ( increaseFOV ) {
					worldCamera.fov ++;
					if (worldCamera.fov > 150)
						worldCamera.fov = 150;
					fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
					pathTracingUniforms.uVLen.value = Math.tan(fovScale);
					pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
				
					cameraIsMoving = true;
					increaseFOV = false;
				}
				if ( decreaseFOV ) {
					worldCamera.fov --;
					if (worldCamera.fov < 1)
						worldCamera.fov = 1;
					fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
					pathTracingUniforms.uVLen.value = Math.tan(fovScale);
					pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
					
					cameraIsMoving = true;
					decreaseFOV = false;
				}
				
				if (increaseFocusDist) {
					focusDistance += 2;
					pathTracingUniforms.uFocusDistance.value = focusDistance;
					cameraIsMoving = true;
					increaseFocusDist = false;
				}
				if (decreaseFocusDist) {
					focusDistance -= 2;
					if (focusDistance < 2)
						focusDistance = 2;
					pathTracingUniforms.uFocusDistance.value = focusDistance;
					cameraIsMoving = true;
					decreaseFocusDist = false;
				}
				
				if (increaseAperture) {
					apertureSize += 1.0;
					if (apertureSize > 200.0)
						apertureSize = 200.0;
					pathTracingUniforms.uApertureSize.value = apertureSize;
					cameraIsMoving = true;
					increaseAperture = false;
				}
				if (decreaseAperture) {
					apertureSize -= 1.0;
					if (apertureSize < 0.0)
						apertureSize = 0.0;
					pathTracingUniforms.uApertureSize.value = apertureSize;
					cameraIsMoving = true;
					decreaseAperture = false;
				}
				
				
				if ( cameraIsMoving ) {
					
					sampleCounter = 1.0;
					
					if ( !cameraRecentlyMoving ) {
						cameraJustStartedMoving = true;
						cameraRecentlyMoving = true;
					}
					
				}
				
				if ( !cameraIsMoving ) {
	
					sampleCounter = 1.0; // for continuous updating of image
					//sampleCounter += 1.0; // for progressive refinement of image
					cameraRecentlyMoving = false;
					
				}
					
				if (cameraControlsObject.position.y < waterLevel)
					cameraUnderWater = 1.0;
				else cameraUnderWater = 0.0;
				
				sunAngle = (elapsedTime * 0.03) % Math.PI;
				sunDirection.set(Math.cos(sunAngle) * 1.2, Math.sin(sunAngle), -Math.cos(sunAngle) * 3.0);
				sunDirection.normalize();	

				pathTracingUniforms.uCameraUnderWater.value = cameraUnderWater;
				pathTracingUniforms.uWaterLevel.value = waterLevel;
				pathTracingUniforms.uSunDirection.value.copy(sunDirection);
				pathTracingUniforms.uTime.value = elapsedTime;
				pathTracingUniforms.uCameraIsMoving.value = cameraIsMoving;
				pathTracingUniforms.uCameraJustStartedMoving.value = cameraJustStartedMoving;
				pathTracingUniforms.uSampleCounter.value = sampleCounter;
				pathTracingUniforms.uRandomVector.value.copy(randomVector.set( Math.random(), Math.random(), Math.random() ));
				// CAMERA
				cameraControlsObject.updateMatrixWorld(true);			
				pathTracingUniforms.uCameraMatrix.value.copy( worldCamera.matrixWorld );
				screenOutputMaterial.uniforms.uOneOverSampleCounter.value = 1.0 / sampleCounter;
				
				cameraInfoElement.innerHTML = "FOV: " + worldCamera.fov + " / Aperture: " + apertureSize.toFixed(2) + " / FocusDistance: " + focusDistance + "<br>" + "Samples: " + sampleCounter;
				
				
				// RENDERING in 3 steps
				
				// STEP 1
				// Perform PathTracing and Render(save) into pathTracingRenderTarget
				// Read previous screenTextureRenderTarget to use as a new starting point to blend with
				renderer.render( pathTracingScene, worldCamera, pathTracingRenderTarget );	
				
				// STEP 2
				// Render(copy) the final pathTracingScene output(above) into screenTextureRenderTarget
				// This will be used as a new starting point for Step 1 above
				renderer.render( screenTextureScene, quadCamera, screenTextureRenderTarget );
				
				// STEP 3
				// Render full screen quad with generated pathTracingRenderTarget in STEP 1 above.
				// After the image is gamma corrected, it will be shown on the screen as the final accumulated output
				renderer.render( screenOutputScene, quadCamera );
						
				
				stats.update();
					
				
			} // end function animate()

		</script>

	</body>
</html>
